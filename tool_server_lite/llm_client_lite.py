#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è½»é‡çº§å¤šæ¨¡æ€LLMå®¢æˆ·ç«¯ - ä¸“ä¾›tool_serverä½¿ç”¨
æ”¯æŒï¼šæ–‡æœ¬ã€å›¾ç‰‡ã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€è¾“å…¥
"""

import os
import yaml
import base64
from pathlib import Path
from typing import Optional
from litellm import completion
import litellm

# å°è¯•å¯¼å…¥ transcribeï¼Œå¦‚æœä¸æ”¯æŒåˆ™ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
try:
    from litellm import transcribe
    HAS_TRANSCRIBE = True
except ImportError:
    HAS_TRANSCRIBE = False
    # å¦‚æœæ²¡æœ‰transcribeï¼Œéœ€è¦ä½¿ç”¨openaiç›´æ¥è°ƒç”¨
    try:
        import openai
        HAS_OPENAI = True
    except ImportError:
        HAS_OPENAI = False


class LLMClientLite:
    """è½»é‡çº§å¤šæ¨¡æ€LLMå®¢æˆ·ç«¯ - ä¾›tool_serverå·¥å…·ä½¿ç”¨"""
    
    def __init__(self, llm_config_path: str = None):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        
        Args:
            llm_config_path: LLMé…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è¯»å–é¡¹ç›®é…ç½®
        """
        # åŠ è½½LLMé…ç½®
        if llm_config_path is None:
            # ä»tool_server_liteç›®å½•æ‰¾åˆ°config
            current_dir = Path(__file__).parent
            config_path = current_dir.parent / "config" / "run_env_config" / "llm_config.yaml"
            
            if not config_path.exists():
                raise FileNotFoundError(f"LLMé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            
            llm_config_path = str(config_path)
        
        if not os.path.exists(llm_config_path):
            raise FileNotFoundError(f"LLMé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {llm_config_path}")
        
        # ä¿å­˜é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåç»­å¯èƒ½çš„é‡è½½ï¼‰
        self.config_path = llm_config_path
        
        with open(llm_config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # è¯»å–é…ç½®
        self.base_url = self.config.get("base_url", "")
        self.api_key = self.config.get("api_key", "")
        self.models = self.config.get("models", [])
        self.figure_models = self.config.get("figure_models", [])
        self.compressor_models = self.config.get("compressor_models", [])
        self.read_figure_models = self.config.get("read_figure_models", [])
        self.temperature = self.config.get("temperature", 0)
        self.max_tokens = self.config.get("max_tokens", 0)
        
        if not self.api_key:
            raise ValueError("æœªé…ç½®APIå¯†é’¥")
        
        if not self.models:
            raise ValueError("æœªé…ç½®å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        
        # é…ç½®LiteLLM
        litellm.set_verbose = False
        litellm.drop_params = True
        
        print(f"âœ… LLMå®¢æˆ·ç«¯é…ç½®å·²åŠ è½½: {llm_config_path}")
    
    def reload_config(self):
        """
        é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
        
        ç”¨äºåœ¨è¿è¡Œæ—¶æ›´æ–°é…ç½®è€Œæ— éœ€é‡å¯æœåŠ¡
        """
        print(f"ğŸ”„ é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶: {self.config_path}")
        
        if not os.path.exists(self.config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # æ›´æ–°é…ç½®
        self.base_url = self.config.get("base_url", "")
        self.api_key = self.config.get("api_key", "")
        self.models = self.config.get("models", [])
        self.figure_models = self.config.get("figure_models", [])
        self.compressor_models = self.config.get("compressor_models", [])
        self.read_figure_models = self.config.get("read_figure_models", [])
        self.temperature = self.config.get("temperature", 0)
        self.max_tokens = self.config.get("max_tokens", 0)
        
        if not self.api_key:
            raise ValueError("æœªé…ç½®APIå¯†é’¥")
        
        if not self.models:
            raise ValueError("æœªé…ç½®å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        
        print(f"âœ… é…ç½®å·²é‡æ–°åŠ è½½")
    
    def vision_query(
        self,
        image_path: str,
        question: str = "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹",
        model: Optional[str] = None
    ) -> str:
        """
        è°ƒç”¨Visionæ¨¡å‹åˆ†æå›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰
            question: è¦é—®çš„é—®é¢˜
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
            
        Returns:
            LLMçš„å“åº”æ–‡æœ¬
            
        Raises:
            FileNotFoundError: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨
            Exception: LLMè°ƒç”¨å¤±è´¥
        """
        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶
        img_path = Path(image_path)
        if not img_path.exists():
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
        with open(img_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # åˆ¤æ–­å›¾ç‰‡æ ¼å¼
        suffix = img_path.suffix.lower()
        mime_type_map = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.webp': 'image/webp'
        }
        mime_type = mime_type_map.get(suffix, 'image/jpeg')
        
        # æ„å»ºVisionæ¶ˆæ¯
        messages = [{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": question
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{mime_type};base64,{image_data}"
                    }
                }
            ]
        }]
        
        # é€‰æ‹©æ¨¡å‹
        if model is None:
            model = self.read_figure_models[0]
        
        # è°ƒç”¨LLM
        try:
            response = completion(
                model=model,
                messages=messages,
                temperature=self.temperature,
                api_key=self.api_key,
                api_base=self.base_url,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶ä¿æŠ¤
            )
            
            # æå–å“åº”
            if response.choices and len(response.choices) > 0:
                return response.choices[0].message.content
            else:
                raise Exception("LLMå“åº”æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘choiceså­—æ®µ")
                
        except Exception as e:
            raise Exception(f"è°ƒç”¨LLM Vision APIå¤±è´¥: {str(e)}")

    def create_image(
        self,
        prompt: str,
        model: Optional[str] = None,
        reference_images: Optional[list[str]] = None,
        size: str = "1024x1024",
        n: int = 1,
        response_format: str = "b64_json"
    ) -> str | list[str]:
        """
        è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›¾ç‰‡ï¼ˆæ”¯æŒå‚è€ƒå›¾ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ figure_models ä¸­çš„ç¬¬ä¸€ä¸ª
            reference_images: å‚è€ƒå›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºå›¾ç‰‡ç¼–è¾‘/é£æ ¼è¿ç§»
            size: å›¾ç‰‡å°ºå¯¸ï¼Œé»˜è®¤ "1024x1024"
            n: ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼Œé»˜è®¤ 1
            response_format: è¿”å›æ ¼å¼ "b64_json" æˆ– "url"ï¼Œé»˜è®¤ "b64_json"
            
        Returns:
            å•å›¾æ—¶è¿”å›ä¸€ä¸ª base64 æ•°æ® URL æˆ– HTTP URL
            å¤šå›¾æ—¶è¿”å› URL åˆ—è¡¨
            
        Note:
            - OpenRouter: ä½¿ç”¨ chat.completions + modalities (+ å‚è€ƒå›¾)
            - å…¶ä»– API: ä½¿ç”¨ litellm.image_generation() (çº¯ç”Ÿæˆ) æˆ– litellm.image_edit() (æœ‰å‚è€ƒå›¾)
        """
        if model is None:
            if self.figure_models:
                # å…¼å®¹å­—ç¬¦ä¸²æˆ–å­—å…¸æ ¼å¼
                first_model = self.figure_models[0]
                model = first_model if isinstance(first_model, str) else first_model.get("name")
            else:
                model = "dall-e-3"
        
        try:
            has_reference = reference_images and len(reference_images) > 0
            print(f"[INFO] è°ƒç”¨å›¾ç‰‡ç”Ÿæˆ API: {model}")
            if has_reference:
                print(f"[INFO] å‚è€ƒå›¾ç‰‡æ•°é‡: {len(reference_images)}")
            if self.base_url:
                print(f"[INFO] ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹: {self.base_url}")
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯ OpenRouter
            is_openrouter = self.base_url and 'openrouter' in self.base_url.lower()
            
            if is_openrouter:
                # OpenRouterï¼šä½¿ç”¨ chat.completions + modalities
                from openai import OpenAI
                
                print(f"[INFO] ä½¿ç”¨ OpenRouter æ–¹å¼")
                
                client = OpenAI(
                    base_url=self.base_url,
                    api_key=self.api_key,
                )
                
                # æ„å»º content
                if has_reference:
                    # æœ‰å‚è€ƒå›¾ï¼šæ„å»ºå¤šæ¨¡æ€ content
                    content = [{"type": "text", "text": prompt}]
                    
                    for img_path_str in reference_images:
                        img_path = Path(img_path_str)
                        if not img_path.exists():
                            raise FileNotFoundError(f"å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨: {img_path_str}")
                        
                        # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
                        with open(img_path, "rb") as image_file:
                            image_data = base64.b64encode(image_file.read()).decode('utf-8')
                        
                        # åˆ¤æ–­å›¾ç‰‡æ ¼å¼
                        suffix = img_path.suffix.lower()
                        mime_type_map = {
                            '.jpg': 'image/jpeg',
                            '.jpeg': 'image/jpeg',
                            '.png': 'image/png',
                            '.gif': 'image/gif',
                            '.webp': 'image/webp'
                        }
                        mime_type = mime_type_map.get(suffix, 'image/jpeg')
                        
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{image_data}"
                            }
                        })
                else:
                    # çº¯æ–‡æœ¬ç”Ÿæˆ
                    content = prompt
                
                # æ„å»º extra_body
                extra_body = {"modalities": ["image", "text"]}
                
                # æ·»åŠ  image_configï¼ˆå®½é«˜æ¯”ï¼‰
                if size and "x" in size:
                    width, height = map(int, size.split("x"))
                    from math import gcd
                    g = gcd(width, height)
                    ratio_w, ratio_h = width // g, height // g
                    aspect_ratio = f"{ratio_w}:{ratio_h}"
                    if aspect_ratio in ["1:1", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]:
                        extra_body["image_config"] = {"aspect_ratio": aspect_ratio}
                
                # è°ƒç”¨ API
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": content}],
                    extra_body=extra_body
                )
                
                # æå–å›¾ç‰‡
                message = response.choices[0].message
                results = []
                
                if hasattr(message, 'images') and message.images:
                    for image in message.images:
                        if isinstance(image, dict):
                            image_url = image.get('image_url', {}).get('url')
                            if image_url:
                                results.append(image_url)
                        elif hasattr(image, 'image_url'):
                            url = getattr(image.image_url, 'url', None)
                            if url:
                                results.append(url)
                    
                    if results:
                        print(f"[INFO] æˆåŠŸç”Ÿæˆ {len(results)} å¼ å›¾ç‰‡")
                        return results[0] if n == 1 else results
                    else:
                        raise Exception("å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾ç‰‡")
                else:
                    raise Exception(f"å“åº”ä¸­æ²¡æœ‰ images å­—æ®µã€‚Message å±æ€§: {dir(message)}")
            
            else:
                # å…¶ä»–ä¾›åº”å•†ï¼ˆGeminiç­‰ï¼‰ï¼šç»Ÿä¸€ä½¿ç”¨ litellm.completion()
                from litellm import completion
                
                print(f"[INFO] ä½¿ç”¨ litellm.completion() æ–¹å¼")
                
                # æ„å»º content
                if has_reference:
                    # æœ‰å‚è€ƒå›¾ï¼šæ„å»ºå¤šæ¨¡æ€ content
                    content = [{"type": "text", "text": prompt}]
                    
                    for img_path_str in reference_images:
                        img_path = Path(img_path_str)
                        
                        # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
                        with open(img_path, "rb") as image_file:
                            image_data = base64.b64encode(image_file.read()).decode('utf-8')
                        
                        # åˆ¤æ–­å›¾ç‰‡æ ¼å¼
                        suffix = img_path.suffix.lower()
                        mime_type_map = {
                            '.jpg': 'image/jpeg',
                            '.jpeg': 'image/jpeg',
                            '.png': 'image/png',
                            '.gif': 'image/gif',
                            '.webp': 'image/webp'
                        }
                        mime_type = mime_type_map.get(suffix, 'image/jpeg')
                        
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{image_data}"
                            }
                        })
                else:
                    # çº¯æ–‡æœ¬ç”Ÿæˆ
                    content = prompt
                
                # æ„å»ºè¯·æ±‚å‚æ•°
                kwargs = {
                    "model": model,
                    "messages": [{"role": "user", "content": content}],
                    "api_key": self.api_key,
                    "timeout": 300,
                    "modalities": ["image", "text"]
                }
                
                # æ·»åŠ  base_urlï¼ˆå¦‚æœæœ‰ï¼‰
                if self.base_url and self.base_url.strip():
                    kwargs["api_base"] = self.base_url
                
                # æ·»åŠ  image_configï¼ˆå®½é«˜æ¯”é…ç½®ï¼‰
                if size and "x" in size:
                    width, height = map(int, size.split("x"))
                    from math import gcd
                    g = gcd(width, height)
                    ratio_w, ratio_h = width // g, height // g
                    aspect_ratio = f"{ratio_w}:{ratio_h}"
                    if aspect_ratio in ["1:1", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]:
                        kwargs["image_config"] = {"aspect_ratio": aspect_ratio}
                
                # è°ƒç”¨ litellm.completion
                response = completion(**kwargs)
                
                # æå–å›¾ç‰‡
                results = []
                if hasattr(response, 'choices') and response.choices:
                    message = response.choices[0].message
                    
                    # æ–¹å¼1ï¼šimages å­—æ®µ
                    if hasattr(message, 'images') and message.images:
                        for image in message.images:
                            if isinstance(image, dict):
                                image_url = image.get('image_url', {}).get('url')
                                if image_url:
                                    results.append(image_url)
                            elif hasattr(image, 'image_url'):
                                url = getattr(image.image_url, 'url', None)
                                if url:
                                    results.append(url)
                    
                    # æ–¹å¼2ï¼šcontent ä¸­çš„ image_url
                    if not results and hasattr(message, 'content'):
                        if isinstance(message.content, list):
                            for part in message.content:
                                if isinstance(part, dict) and part.get('type') == 'image_url':
                                    url = part.get('image_url', {}).get('url')
                                    if url:
                                        results.append(url)
                
                if results:
                    print(f"[INFO] æˆåŠŸç”Ÿæˆ {len(results)} å¼ å›¾ç‰‡")
                    return results[0] if n == 1 else results
                else:
                    if hasattr(response, 'choices') and response.choices:
                        message = response.choices[0].message
                        raise Exception(f"å“åº”ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ã€‚Message å†…å®¹: {message.content[:200] if hasattr(message, 'content') else 'N/A'}")
                    else:
                        raise Exception("å“åº”æ ¼å¼å¼‚å¸¸")
                
        except Exception as e:
            raise Exception(f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {str(e)}")
    
    def audio_query(
        self,
        audio_path: str,
        question: str = "è¯·æè¿°è¿™æ®µéŸ³é¢‘çš„å†…å®¹",
        model: Optional[str] = None
    ) -> str:
        """
        è°ƒç”¨Audioæ¨¡å‹åˆ†æéŸ³é¢‘
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰
            question: è¦é—®çš„é—®é¢˜
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
            
        Returns:
            LLMçš„å“åº”æ–‡æœ¬ï¼ˆåŒ…å«è½¬å½•å†…å®¹å’Œåˆ†æç»“æœï¼‰
            
        Raises:
            FileNotFoundError: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨
            Exception: LLMè°ƒç”¨å¤±è´¥
        
        æµç¨‹:
        1. ä½¿ç”¨ Whisper API å°†éŸ³é¢‘è½¬å½•ä¸ºæ–‡æœ¬
        2. æ ¹æ®é—®é¢˜åˆ†æè½¬å½•å†…å®¹å¹¶è¿”å›ç»“æœ
        """
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
        audio_file = Path(audio_path)
        if not audio_file.exists():
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        # åˆ¤æ–­éŸ³é¢‘æ ¼å¼
        suffix = audio_file.suffix.lower()
        supported_formats = {
            '.mp3': 'audio/mpeg',
            '.mp4': 'audio/mp4',
            '.mpeg': 'audio/mpeg',
            '.mpga': 'audio/mpeg',
            '.m4a': 'audio/mp4',
            '.wav': 'audio/wav',
            '.webm': 'audio/webm'
        }
        
        if suffix not in supported_formats:
            raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {suffix}ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(supported_formats.keys())}")
        
        # é€‰æ‹©æ¨¡å‹
        if model is None:
            model = self.models[0]
        
        try:
            # æ­¥éª¤1: è½¬å½•éŸ³é¢‘ä¸ºæ–‡æœ¬
            print(f"ğŸ“ æ­£åœ¨è½¬å½•éŸ³é¢‘: {audio_path}")
            
            transcript_text = ""
            
            if HAS_TRANSCRIBE:
                # ä½¿ç”¨ litellm çš„ transcribe åŠŸèƒ½
                transcript = litellm.transcribe(
                    model="whisper-1",
                    file=str(audio_file),
                    api_key=self.api_key,
                    api_base=self.base_url,
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶ä¿æŠ¤
                )
                
                # æå–è½¬å½•æ–‡æœ¬
                if isinstance(transcript, dict) and 'text' in transcript:
                    transcript_text = transcript['text']
                elif isinstance(transcript, str):
                    transcript_text = transcript
                else:
                    transcript_text = str(transcript)
            
            elif HAS_OPENAI:
                # ä½¿ç”¨ OpenAI ç›´æ¥è°ƒç”¨
                with open(audio_file, "rb") as f:
                    transcript = openai.Audio.transcribe(
                        "whisper-1",
                        f,
                        api_key=self.api_key,
                        api_base=self.base_url if self.base_url else None
                    )
                    transcript_text = transcript['text']
            
            else:
                raise Exception("æœªå®‰è£…å¿…è¦çš„åº“ï¼ˆlitellm æˆ– openaiï¼‰")
            
            print(f"âœ… è½¬å½•å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(transcript_text)} å­—ç¬¦")
            
            # æ­¥éª¤2: å¯¹è½¬å½•å†…å®¹è¿›è¡Œåˆ†æ
            messages = [{
                "role": "user",
                "content": f"ä»¥ä¸‹æ˜¯éŸ³é¢‘è½¬å½•å†…å®¹ï¼š\n\n{transcript_text}\n\nè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{question}"
            }]
            
            response = completion(
                model=model,
                messages=messages,
                temperature=self.temperature,
                api_key=self.api_key,
                api_base=self.base_url,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶ä¿æŠ¤
            )
            
            # æå–å“åº”
            if response.choices and len(response.choices) > 0:
                analysis_result = response.choices[0].message.content
                
                # è¿”å›åŒ…å«è½¬å½•å’Œåˆ†æçš„å®Œæ•´ç»“æœ
                return f"ã€éŸ³é¢‘è½¬å½•ã€‘\n{transcript_text}\n\nã€åˆ†æç»“æœã€‘\n{analysis_result}"
            else:
                raise Exception("LLMå“åº”æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘choiceså­—æ®µ")
                
        except Exception as e:
            raise Exception(f"è°ƒç”¨éŸ³é¢‘åˆ†æAPIå¤±è´¥: {str(e)}")
    
    def text_query(
        self,
        text: str,
        question: str,
        model: Optional[str] = None
    ) -> str:
        """
        é€šç”¨æ–‡æœ¬åˆ†æï¼ˆé€‚ç”¨äºè®ºæ–‡ã€æ–‡æ¡£ç­‰é•¿æ–‡æœ¬ï¼‰
        
        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬å†…å®¹
            question: é—®é¢˜æˆ–æŒ‡ä»¤
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
            
        Returns:
            LLMçš„å“åº”æ–‡æœ¬
            
        Raises:
            Exception: LLMè°ƒç”¨å¤±è´¥
        """
        # æ„å»ºæ¶ˆæ¯
        messages = [{
            "role": "user",
            "content": f"ä»¥ä¸‹æ˜¯å†…å®¹ï¼š\n\n{text}\n\n{question}"
        }]
        
        # é€‰æ‹©æ¨¡å‹
        if model is None:
            model = self.models[0]
        
        # è°ƒç”¨LLM
        try:
            response = completion(
                model=model,
                messages=messages,
                temperature=self.temperature,
                api_key=self.api_key,
                api_base=self.base_url,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶ä¿æŠ¤
            )
            
            # æå–å“åº”
            if response.choices and len(response.choices) > 0:
                return response.choices[0].message.content
            else:
                raise Exception("LLMå“åº”æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘choiceså­—æ®µ")
                
        except Exception as e:
            raise Exception(f"è°ƒç”¨LLMæ–‡æœ¬åˆ†æAPIå¤±è´¥: {str(e)}")


# å…¨å±€å•ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œæ”¯æŒé…ç½®æ–‡ä»¶çƒ­é‡è½½ï¼‰
_client_instance: Optional[LLMClientLite] = None
_config_file_path: Optional[str] = None
_config_file_mtime: Optional[float] = None


def get_llm_client(force_reload: bool = False) -> LLMClientLite:
    """
    è·å–LLMå®¢æˆ·ç«¯å•ä¾‹ï¼ˆæ”¯æŒé…ç½®æ–‡ä»¶çƒ­é‡è½½ï¼‰
    
    Args:
        force_reload: æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½é…ç½®
    
    Returns:
        LLMClientLiteå®ä¾‹
        
    Note:
        - è‡ªåŠ¨æ£€æµ‹é…ç½®æ–‡ä»¶ä¿®æ”¹æ—¶é—´ï¼Œå¦‚æœé…ç½®æ–‡ä»¶è¢«ä¿®æ”¹ï¼Œä¼šè‡ªåŠ¨é‡æ–°åŠ è½½
        - ä¹Ÿå¯ä»¥é€šè¿‡ force_reload=True å¼ºåˆ¶é‡æ–°åŠ è½½
    """
    global _client_instance, _config_file_path, _config_file_mtime
    
    # ç¡®å®šé…ç½®æ–‡ä»¶è·¯å¾„
    if _config_file_path is None:
        current_dir = Path(__file__).parent
        _config_file_path = str(current_dir.parent / "config" / "run_env_config" / "llm_config.yaml")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(_config_file_path):
        if _client_instance is None:
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {_config_file_path}")
        # é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ä½†å·²æœ‰å®ä¾‹ï¼Œè¿”å›ç°æœ‰å®ä¾‹
        return _client_instance
    
    # è·å–å½“å‰é…ç½®æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
    current_mtime = os.path.getmtime(_config_file_path)
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°åŠ è½½
    need_reload = (
        force_reload or 
        _client_instance is None or 
        _config_file_mtime is None or 
        current_mtime != _config_file_mtime
    )
    
    if need_reload:
        if _config_file_mtime is not None and current_mtime != _config_file_mtime:
            print(f"ğŸ”„ æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜åŒ–ï¼Œé‡æ–°åŠ è½½é…ç½®...")
        
        _client_instance = LLMClientLite()
        _config_file_mtime = current_mtime
    
    return _client_instance


def reload_llm_client() -> LLMClientLite:
    """
    å¼ºåˆ¶é‡æ–°åŠ è½½LLMå®¢æˆ·ç«¯é…ç½®
    
    Returns:
        é‡æ–°åŠ è½½åçš„LLMClientLiteå®ä¾‹
    """
    return get_llm_client(force_reload=True)


if __name__ == "__main__":
    # æµ‹è¯•LLMå®¢æˆ·ç«¯ - å›¾ç‰‡ç¼–è¾‘åŠŸèƒ½
    try:
        client = get_llm_client()
        print(f"âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"   å¯ç”¨æ¨¡å‹: {client.models}")
        print(f"   å›¾ç‰‡ç”Ÿæˆæ¨¡å‹: {client.figure_models}")
        print(f"   Base URL: {client.base_url}")
        print("\n" + "="*60)
        
        # æµ‹è¯•å›¾ç‰‡ç”Ÿæˆï¼ˆå¸¦å‚è€ƒå›¾ï¼‰ï¼šèåˆä¸¤å¼ å›¾
        print("\nğŸ¨ æµ‹è¯•å›¾ç‰‡ç”ŸæˆåŠŸèƒ½ï¼ˆå¸¦å‚è€ƒå›¾ï¼‰ï¼šèåˆä¸¤å¼ å›¾è¡¨...")
        
        image1_path = "/Users/chenglin/Desktop/research/agent_framwork/vscode_version/web-use/test_image/7.1.png"
        image2_path = "/Users/chenglin/Desktop/research/agent_framwork/vscode_version/web-use/test_image/7.2.png"
        
        prompt = """
        è¯·å°†è¿™ä¸¤å¼ æ•°æ®å¯è§†åŒ–å›¾è¡¨èåˆæˆä¸€å¼ ç»¼åˆå›¾è¡¨ã€‚
        
        è¦æ±‚ï¼š
        1. ä¿ç•™ä¸¤å¼ å›¾çš„æ ¸å¿ƒä¿¡æ¯å’Œæ•°æ®ç‚¹
        2. ä½¿ç”¨ç»Ÿä¸€çš„é…è‰²æ–¹æ¡ˆ
        3. åˆç†å¸ƒå±€ï¼Œä¸Šä¸‹æˆ–å·¦å³æ’åˆ—
        4. æ·»åŠ æ¸…æ™°çš„æ ‡é¢˜è¯´æ˜è¿™æ˜¯ç®—æ³•æ€§èƒ½å¯¹æ¯”åˆ†æ
        5. ç¡®ä¿å›¾ä¾‹å’Œåæ ‡è½´æ ‡ç­¾æ¸…æ™°å¯è¯»
        """
        
        output_path = "/Users/chenglin/Desktop/research/agent_framwork/vscode_version/web-use/test_image/7_merged.png"
        
        print(f"ğŸ“· å‚è€ƒå›¾ç‰‡1: {image1_path}")
        print(f"ğŸ“· å‚è€ƒå›¾ç‰‡2: {image2_path}")
        print(f"ğŸ’¾ è¾“å‡ºè·¯å¾„: {output_path}")
        print(f"ğŸ“ æç¤ºè¯: {prompt.strip()[:100]}...")
        
        result = client.create_image(
            prompt=prompt,
            reference_images=[image1_path, image2_path],
            size="1792x1024",  # 16:9 æ¯”ä¾‹ï¼Œé€‚åˆå®½å±å±•ç¤º
            n=1,
            response_format="b64_json"
        )
        
        # ä¿å­˜ç»“æœ
        import base64
        if isinstance(result, str):
            # å•ä¸ªç»“æœ
            if result.startswith("data:"):
                # base64 æ ¼å¼
                image_data = result.split(",")[1]
            else:
                image_data = result
            
            image_bytes = base64.b64decode(image_data)
            with open(output_path, 'wb') as f:
                f.write(image_bytes)
            
            print(f"\nâœ… å›¾ç‰‡ç¼–è¾‘æˆåŠŸï¼")
            print(f"   ä¿å­˜ä½ç½®: {output_path}")
            print(f"   æ–‡ä»¶å¤§å°: {len(image_bytes) / 1024:.2f} KB")
        else:
            # å¤šä¸ªç»“æœ
            print(f"\nâœ… ç”Ÿæˆäº† {len(result)} å¼ å›¾ç‰‡")
            for idx, img_data in enumerate(result):
                save_path = output_path.replace(".png", f"_{idx}.png")
                if img_data.startswith("data:"):
                    img_data = img_data.split(",")[1]
                image_bytes = base64.b64decode(img_data)
                with open(save_path, 'wb') as f:
                    f.write(image_bytes)
                print(f"   å›¾ç‰‡ {idx+1}: {save_path}")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

